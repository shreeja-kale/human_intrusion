import cv2
import os
import time
import gc
import tkinter as tk
from PIL import Image, ImageTk
import threading

# --- Setup ---
output_folder = "/home/root/human_images/"
os.makedirs(output_folder, exist_ok=True)

prototxt_path = "mobilenet_ssd/MobileNetSSD_deploy.prototxt"
model_path = "mobilenet_ssd/MobileNetSSD_deploy.caffemodel"
net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)

CLASSES = ["background", "aeroplane", "bicycle", "bird", "boat",
           "bottle", "bus", "car", "cat", "chair",
           "cow", "diningtable", "dog", "horse",
           "motorbike", "person", "pottedplant", "sheep",
           "sofa", "train", "tvmonitor"]

RTSP_URL = "rtsp://vmukti:vmukti%23907@192.168.1.88/1"
cam = cv2.VideoCapture(RTSP_URL, cv2.CAP_FFMPEG)
cam.set(cv2.CAP_PROP_BUFFERSIZE, 1)

img_counter = 0
capture_interval = 60  # seconds
last_capture_time = time.time()

# --- Tkinter root initialized once ---
root = tk.Tk()
root.withdraw()  # Hide the root window

# --- Show Popup Function ---
def show_popup_img(img):
    popup = tk.Toplevel()
    popup.title("Human Intrusion Alert!")
    popup.geometry("700x400+400+200")
    popup.attributes("-topmost", True)

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img_pil = Image.fromarray(img_rgb).resize((640, 360))
    photo = ImageTk.PhotoImage(img_pil)

    panel = tk.Label(popup, image=photo)
    panel.image = photo
    panel.pack()

    # Auto-close in 30 sec
    popup.after(30000, popup.destroy)

# --- Main Loop ---
while True:
    ret, frame = cam.read()
    if not ret or frame is None:
        print("[⚠️] Failed to grab frame. Reconnecting...")
        cam.release()
        time.sleep(2)
        cam = cv2.VideoCapture(RTSP_URL, cv2.CAP_FFMPEG)
        cam.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        continue

    frame = cv2.resize(frame, (960, 540))
    cv2.imshow('Cargo Monitoring', frame)

    current_time = time.time()
    if current_time - last_capture_time >= capture_interval:
        (h, w) = frame.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)
        net.setInput(blob)
        detections = net.forward()

        found_human = False
        for i in range(detections.shape[2]):
            confidence = detections[0, 0, i, 2]
            if confidence > 0.05:
                idx = int(detections[0, 0, i, 1])
                if CLASSES[idx] == "person":
                    found_human = True
                    box = detections[0, 0, i, 3:7] * [w, h, w, h]
                    (startX, startY, endX, endY) = box.astype("int")
                    if (endX - startX) > 50 and (endY - startY) > 50:
                        cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)
                        label = f"Person: {confidence * 100:.2f}%"
                        cv2.putText(frame, label, (startX, startY - 10),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        if found_human:
            print("[✅] Human detected. Showing popup and closing main display.")
            cv2.destroyAllWindows()  # Close OpenCV display immediately

            # Show popup (in main thread, not child thread)
            show_popup_img(frame.copy())

            # Optional: reinitialize camera after popup
            cam.release()
            time.sleep(1)
            cam = cv2.VideoCapture(RTSP_URL, cv2.CAP_FFMPEG)
            cam.set(cv2.CAP_PROP_BUFFERSIZE, 1)

            # reset timer and count
            img_counter += 1
            last_capture_time = current_time
            continue

        last_capture_time = current_time
        del blob, detections
        gc.collect()

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# --- Cleanup ---
cam.release()
cv2.destroyAllWindows()
